# QREA Fast Testing Configuration
# Optimized for quick testing and debugging

# ============================================================================
# ENVIRONMENT CONFIGURATION
# ============================================================================
environment:
  name: "warehouse_3d"
  grid_size: [50, 50]
  num_robots: 3  # REDUCED from 5 for speed
  num_packages: 50  # REDUCED from 100
  num_stations: 4
  
  package_spawn_rate: 0.5
  package_types:
    standard: {weight: 5.0, priority: 1, reward: 100.0}  # 10x increase for learning
    express: {weight: 3.0, priority: 2, reward: 200.0}   # 8x increase for learning
    fragile: {weight: 2.0, priority: 3, reward: 300.0}   # 7.5x increase for learning
  
  stations:
    pickup: [5, 5]
    delivery_a: [45, 5]
    delivery_b: [45, 45]
    delivery_c: [5, 45]
  
  dt: 0.1
  max_episode_steps: 500  # REDUCED from 5000
  
  robot:
    radius: 0.5
    max_speed: 2.0
    max_acceleration: 1.0
    max_angular_velocity: 1.57
    battery_capacity: 1000.0
    battery_drain_idle: 0.1
    battery_drain_moving: 0.5
    battery_drain_carrying: 1.0
    charging_rate: 5.0
  
  sensors:
    lidar:
      num_rays: 32
      max_range: 10.0
      noise_std: 0.05
    gps:
      noise_std: 0.1
    imu:
      noise_std: 0.01

# ============================================================================
# AGENT ARCHITECTURE
# ============================================================================
agent:
  world_model:
    latent_dim: 128  # REDUCED from 256
    hidden_dim: 256  # REDUCED from 512
    stochastic_dim: 32
    deterministic_dim: 256  # REDUCED from 512
    num_layers: 2  # REDUCED from 3
    activation: "elu"
    
    encoder:
      hidden_dims: [256, 256]  # REDUCED
    decoder:
      hidden_dims: [256, 256]  # REDUCED
    reward_predictor:
      hidden_dims: [256, 128]  # REDUCED
    discount_predictor:
      hidden_dims: [256, 128]  # REDUCED
    
  policy:
    hidden_dims: [256, 256]  # REDUCED from [512, 512, 256]
    action_dim: 3
    activation: "elu"
    log_std_min: -10
    log_std_max: 2
    
  value:
    hidden_dims: [256, 256]  # REDUCED
    activation: "elu"
    
  intrinsic:
    novelty:
      enabled: true
      weight: 0.1
      network_dim: 256  # REDUCED from 512
      predictor_lr: 0.0001
      
    competence:
      enabled: true
      weight: 0.05
      history_length: 50  # REDUCED from 100
      
    empowerment:
      enabled: true
      weight: 0.05
      planning_horizon: 3  # REDUCED from 5
      use_infonce: true
      num_negatives: 8  # REDUCED from 16
      temperature: 0.1
      lookahead_horizon: 3

# ============================================================================
# UPRT FIELD CONFIGURATION
# ============================================================================
uprt:
  field:
    grid_resolution: [50, 50]  # REDUCED from [100, 100]
    update_rate: 5  # REDUCED from 10
    diffusion_coeff: 0.1
    decay_rate: 0.05
    
  symbols:
    num_prototypes: 25  # REDUCED from 50
    embedding_dim: 64  # REDUCED from 128
    detection_threshold: 0.7
    emergence_threshold: 0.85
    
  resonance:
    kernel_type: "gaussian"
    kernel_width: 2.0
    coherence_threshold: 0.6
    
  consciousness_field:
    enabled: true
    interaction_strength: 1.0
  
  genetic_field:
    enabled: true
    inheritance_rate: 0.1
    
  resonance_field:
    enabled: true
    coupling_strength: 0.5
  
  solver:
    method: "explicit"  # CHANGED from semi_implicit for speed
    use_fft: false  # DISABLED for small grids
    cfl_safety: 0.8

# ============================================================================
# LEARNING CONFIGURATION
# ============================================================================
learning:
  optimizer: "adam"
  learning_rate: 0.0003
  weight_decay: 0.0001
  grad_clip: 10.0
  
  amp: true  # Keep AMP for speedup
  amp_dtype: "float16"
  
  ensemble_world_models: 1  # DISABLED ensemble (was 3)
  
  world_model:
    batch_size: 32  # REDUCED from 50
    sequence_length: 25  # REDUCED from 50
    free_nats: 3.0
    kl_weight: 1.0
    
  actor_critic:
    batch_size: 32  # REDUCED from 50
    sequence_length: 10  # REDUCED from 15
    discount: 0.99
    lambda_gae: 0.95
    entropy_weight: 0.001
    
  replay:
    capacity: 100000  # REDUCED from 1000000
    prioritized: true
    alpha: 0.6
    beta_start: 0.4
    beta_end: 1.0
    beta_anneal_steps: 50000  # REDUCED from 100000
    
  imagination:
    horizon: 10  # REDUCED from 15
    num_trajectories: 5  # REDUCED from 10

# ============================================================================
# EVOLUTION CONFIGURATION  
# ============================================================================
evolution:
  population_size: 10  # REDUCED from 20
  elite_size: 2  # REDUCED from 4
  
  selection:
    method: "tournament"
    tournament_size: 3
    
  crossover:
    rate: 0.7
    method: "uniform"
    alpha: 0.5
    
  mutation:
    rate: 0.2
    std: 0.1
    adaptive: true
    
  cma_es:
    enabled: false  # DISABLED for speed
    
  heritability:
    track: false  # DISABLED for speed
    
  hgt:
    enabled: true
    rate: 0.1
    transfer_method: "best_practice"
    
  inheritance:
    darwinian_weight: 0.5
    baldwinian_weight: 0.3
    lamarckian_weight: 0.2
    
  generations: 50  # REDUCED from 100
  evaluation_episodes: 3  # REDUCED from 5
  parallel_eval: true

# ============================================================================
# COMMUNICATION / LANGUAGE
# ============================================================================
communication:
  language:
    enabled: true
    vocab_size: 50  # REDUCED from 100
    message_length: 5  # REDUCED from 10
    embedding_dim: 32  # REDUCED from 64
    
  channel:
    range: 15.0
    bandwidth: 10
    noise_level: 0.05
    
  pragmatics:
    success_threshold: 0.8
    update_rate: 0.01

# ============================================================================
# SAFETY CONFIGURATION
# ============================================================================
safety:
  collision:
    min_distance: 1.0
    soft_constraint_weight: 100.0
    hard_constraint: true
    
  barrier_lyapunov:
    enabled: false  # DISABLED for speed
    
  patchgate:
    enabled: false  # DISABLED for speed
    
  constraints:
    max_velocity: 2.5
    min_battery_reserve: 100.0
    safe_zone_required: true

# ============================================================================
# SIMULATION CONFIGURATION (OPTIMIZED FOR SPEED!)
# ============================================================================
simulation:
  # Training - MUCH SHORTER
  num_epochs: 100  # REDUCED from 1000
  steps_per_epoch: 1000  # REDUCED from 10000
  eval_interval: 2  # Evaluate every 2 epochs
  eval_episodes: 3  # REDUCED from 10
  
  # Checkpointing
  checkpoint_interval: 5  # Save more frequently
  save_replay_buffer: false
  
  # Logging
  log_interval: 50  # REDUCED from 100
  tensorboard: true
  wandb: false
  log_video: false  # DISABLED for speed
  video_interval: 100
  
  # Device
  device: "cuda"
  num_workers: 4
  seed: 42

# ============================================================================
# METRICS & EVALUATION
# ============================================================================
metrics:
  primary:
    - throughput
    - efficiency
    - success_rate
    - collision_rate
    
  secondary:
    - waiting_time
    - travel_distance
    - battery_usage
    - coordination_score
    
  emergent:
    - symbol_diversity
    - language_efficiency
    - field_coherence
    - collective_intelligence

# ============================================================================
# EXPERIMENT CONFIGURATION
# ============================================================================
experiment:
  name: "qrea_warehouse_fast_test"
  description: "Fast testing configuration for debugging"
  tags: ["qrea", "warehouse", "fast", "test"]
  
  baselines:
    - "random"
    - "greedy"
    
  ablations:
    - "no_intrinsic"

# ============================================================================
# PERFORMANCE OPTIMIZATIONS APPLIED
# ============================================================================
# 1. Reduced robots: 5 → 3
# 2. Reduced packages: 100 → 50
# 3. Reduced episode length: 5000 → 500 steps
# 4. Reduced network sizes: 512 → 256 hidden dims
# 5. Disabled ensemble: 3 → 1 world models
# 6. Reduced batch sizes: 50 → 32
# 7. Reduced sequence lengths: 50 → 25
# 8. Smaller replay buffer: 1M → 100K
# 9. Fewer epochs: 1000 → 10
# 10. Fewer steps per epoch: 10000 → 500
# 11. Disabled video logging
# 12. Disabled PatchGate and BLF
# 13. Disabled CMA-ES evolution
# 14. Reduced population: 20 → 10
# 15. Simplified UPRT solver
# 16. Smaller UPRT grid: 100x100 → 50x50
#
# Expected speedup: 50-100x faster!
# Total steps: 10 epochs × 500 steps = 5,000 (vs 10,000,000!)
